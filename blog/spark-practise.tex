% Created 2017-03-21 Tue 17:35
% Intended LaTeX compiler: pdflatex
\documentclass[11pt,a4paper]{article}
\usepackage{fontspec}
\usepackage{xeCJK}
\setCJKmainfont[BoldFont=FandolSong-Bold.otf,ItalicFont=FandolKai-Regular.otf]{FandolSong-Regular.otf}
\setCJKsansfont[BoldFont=FandolHei-Bold.otf]{FandolHei-Regular.otf}
\setCJKmonofont{FandolFang-Regular.otf}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{listings}
\defaultfontfeatures{Mapping=tex-text}
\usepackage{geometry}
\usepackage{verbatim}
\usepackage{fixltx2e}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{parskip}
\setlength{\parindent}{15pt}
\usepackage{indentfirst}
\geometry{a4paper, textwidth=6.5in, textheight=10in,
            marginparsep=7pt, marginparwidth=.6in}
\tolerance=1000
\pagestyle{empty}
\author{enzo liu}
\date{2017-03-20 Thu}
\title{Spark 入门实操}
\hypersetup{
 pdfauthor={enzo liu},
 pdftitle={Spark 入门实操},
 pdfkeywords={spark},
 pdfsubject={spark},
 pdfcreator={Emacs 25.1.1 (Org mode 9.0.5)},
 pdflang={English}}
\begin{document}

\maketitle

\section*{背景}
\label{sec:org10de301}
内网服务器的 spark 又跑不动了... 所以在阿里云上买两台机器, 严肃点的部署一下.
顺便把之前的 pyspark 脚本也迁移到 scala 上，可以利用起我们 java 下的资源.

\section*{部署环境}
\label{sec:org09331f6}
\begin{itemize}
\item 机器
阿里云 2 台 4 核 16g
\item 依赖软件
\begin{itemize}
\item ansible-2.0
\item spark-2.1
\item jdk-1.8
\end{itemize}
\end{itemize}

\section*{部署过程}
\label{sec:org906de3e}
\begin{quote}
为了后续添加 slave 方便，在 ansible 的脚本上花了很大的功夫。
根据 master 以及 slave 的 inventory 配置
\begin{itemize}
\item 自动配置 authorized\_keys
\item 自动配置 master 的 ssh\_config
\item 自动 配置 nfs, 以及 mount master 的工作区目录
\end{itemize}
\end{quote}

具体 ansible 脚本的执行步骤大致如下:
\begin{itemize}
\item 安装 jdk
\item 安装 spark
\item 生成以及拷贝 spark 的配置文件
\begin{description}
\item[{conf/slaves}] 配置 ssh 的别名
\item[{conf/spark-defaults.conf}] 配置 master 的 url
\item[{conf/spark-env.sh}] 配置 JAVA\_HOME, SPARK\_HOME, 各类 MEMORY
\end{description}
\item 配置 master 的 ssh\_key, 以及添加到 slave 的 authorized\_keys 中
\begin{itemize}
\item spark 的 start-all.sh 中通过 ssh 来启动所有的 slave 的 worker
\end{itemize}
\item 配置 nfs 共享工作区
\begin{itemize}
\item 运行模式下需要所有的 worker 都能根据地址访问到所要执行的 jar
\end{itemize}
\end{itemize}

\section*{发布方式}
\label{sec:org9e566a3}
\begin{itemize}
\item 打包
\texttt{sbt assembly}
\item 上传
\texttt{scp \$WORKING\_DIR/target/*.jar spark:/home/spark/workspace/}
\end{itemize}

\section*{执行方式}
\label{sec:org812e1d6}
\texttt{crontab} 定期调度
\lstset{frame=single,backgroundcolor=\color[gray]{0.95},identifierstyle=\ttfamily,keywordstyle=\color[rgb]{0,0,1},commentstyle=\color[rgb]{0.133,0.545,0.133},stringstyle=\color[rgb]{0.627,0.126,0.941},basicstyle=\scriptsize,extendedchars=true,breaklines=true,prebreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},columns=fixed,keepspaces=true,showstringspaces=false,numbers=left,xleftmargin=.25in,xrightmargin=.25in,numberstyle=\tiny,language=shell,label= ,caption= ,captionpos=b}
\begin{lstlisting}
$SPARK_HOME/bin/spark-submit --class *** /home/spark/workspace/***
\end{lstlisting}

\section*{App 示例}
\label{sec:org9f9ce4c}
\lstset{frame=single,backgroundcolor=\color[gray]{0.95},identifierstyle=\ttfamily,keywordstyle=\color[rgb]{0,0,1},commentstyle=\color[rgb]{0.133,0.545,0.133},stringstyle=\color[rgb]{0.627,0.126,0.941},basicstyle=\scriptsize,extendedchars=true,breaklines=true,prebreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},columns=fixed,keepspaces=true,showstringspaces=false,numbers=left,xleftmargin=.25in,xrightmargin=.25in,numberstyle=\tiny,language=scala,label= ,caption= ,captionpos=b}
\begin{lstlisting}
val idsRDD = odpsOps.readTable(project, table, pr, read, numPartitions)
  .filter(_.schema.schema == "activity_detail").filter(_.time.isAfter(start)) // 保留最近一个月的访问记录
  .flatMap(r => toInt(r.schema.key).map(((r.dvid, r.time.toString(DateTimeFormat.shortDate)), _))) //记录转换成设备号，访问日期，演出 ID 的各式
  .groupBy(_._1).map(_._2.map(_._2)).map(_.toSet) //根据设备号和访问日期聚合，且仅保留演出 ID 的信息
  .filter(ids => ids.size > 1 && ids.size < 5) //只保留访问的演出在 2-4 之间的数据
val weightRdd = generate(idsRDD)

def listToPair[T](ls:List[T]):List[(T,T)] = ls match {
  case Nil => List()
  case a::ls => ls.map((a,_)) ++ listToPair(ls)
}

def sort(p:(Int,Int)) : (Int,Int) = if (p._1 < p._2) p else p.swap

def toScore(elementNums:Map[Int,Long], pairNums:((Int,Int),Int)) : ((Int,Int), Double) = {
  val ((a,b),n) = pairNums
  ((a,b), n / Math.sqrt(1.0*elementNums(a)*elementNums(b)))
}

def generate(ls:RDD[Set[Int]]) : RDD[((Int,Int),Double)] = {
  val flattened = ls.flatMap(s=>listToPair(s.toList))
  val elementNumbers = ls.flatMap(_.toList).countByValue()
  flattened.groupBy(sort).mapValues(_.size)
    .map(r=>toScore(elementNumbers,r))
    .flatMap(withReverse)
}

def withReverse(res: ((Int,Int), Double)) = {
  val ((activityId, relatedId), weight) = res
  Seq(res, ((relatedId, activityId),weight))
}
\end{lstlisting}

\section*{执行结果}
\label{sec:org925a475}
同样的功能，由于
\begin{itemize}
\item 数据源切换到了阿里云的 odps(内网带宽千兆可以跑满)
\item 减少了 nginx 日志的解析工作(odps 里可以相对结构化的存储信息)
\end{itemize}
原本 2 小时的执行任务，现在 4 分钟就能搞定...
\end{document}